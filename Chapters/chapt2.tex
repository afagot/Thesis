% Header
\renewcommand\evenpagerightmark{{\scshape\small Chapter 2}}
\renewcommand\oddpageleftmark{{\scshape\small Investigating the \si{TeV} scale}}

\renewcommand{\bibname}{References}

\hyphenation{}

\chapter[Investigating the \si{TeV} scale]%
{Investigating the \si{TeV} scale}
\label{chapt:2}

	Throughout history, physics experiment became more and more powerful in order to investigate finer details of nature to help understanding the building blocks of matter and the fundamental interactions that bind them in the microscopic world. Nowadays, the \acl{SM} of particle physics is the most accurate theory designed to explain the behaviour of particles and is able to make very precise predictions that are constantly verified. Nevertheless, some hints of new physics are visible as bricks are still missing to have a global description of the Universe.
	
	To highlight the limits of the SM and test the different alternative theories, ever more powerful machines are needed. It is in this context that the \acl{LHC} has been thought and built to accelerate and collide particles at energies exceeding anything that had been done before. Higher collision energies and high pile-up imply the use of enormous detectors to measure the properties of the interaction products. The \acl{CMS} is a multipurpose experiment that have been designed to study the proton-proton collisions of the LHC and give answers on various high energy physics scenarios such as different \acf{SUSY} extensions to the \acl{SM} or Extra Dimensions models.\\
	
	This Chapter will be the occasion to go through the history of the \acl{SM} of Particle Physics to understand the research conducted today in \acf{HEP} facilities. From the discovery of the atom and of its inner structure to the development of the theories governing the fundamental interactions, all the elements leading to the construction SM will be discussed. Furthermore, highlight on the \acf{BSM} will be given to replace the document in the context of today's research. Finally, a full description of the LHC and of the CMS detector will be provided.

\section{The \acl{SM} of Particle Physics}
\label{chapt2:sec:SM}

	In the early \St{21} century it is now widely accepted that matter is made of elementary blocks referred to as \textit{elementary particles}. The physics theory that classifies and describes the best the behaviour and interaction of such elementary particles is the so-called \acl{SM}. The SM formalizes 3 of the 4 fondamental interactions (electromagnetic, weak and strong interactions). It's development happened since the 1960s thanks to a strong collaboration between theoretical and experimental physicists.

	\subsection{A history of particle physics}
	\label{chapt2:ssec:history}
	
	The idea that nature is composed of elementary bricks, called \textit{atomism}, is not contemporary as it was already discussed by Indian or Greek philosophers during antiquity. In Greece, atomism has been rejected by \textit{Aristotelianism} as the existance of \textit{atoms} would imply the existance of a void that would violate the physical principles of Aristotle philosophy. Aristotelianism has been considered as a reference in the european area until the \Th{15} century. With the \textit{Rinascimento}, antic text and history started to be more deeply studied. The re-discovery of Platon's philosophy would allow to open the door to alternative theories and give a new approach to natural sciences where experimentation would become central. A new era of knowledge was starting. By the begining of the \Th{17} century, atomism was re-discovered by philosophers. The very first attempt at estimating the number of \textit{particles} in a volume would be provided by Magnenus in 1646 by calculating that the number of \textit{particles} in a stick of incense~\cite{MAGNEGNUS1646}. He would find a value of the order of $10^{18}$ simply by considering the time necessary to smell it everywhere in a large church after the stick was lit on. It is now known that this number only falls short by 1 order of magnitude.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{fig/chapt2/Fraunhofer.jpg}
		\caption{\label{fig:spectral-lines} Solar spectrum with spectral lines as it appeared visually to Fraunhofer.}
	\end{figure}
	
	An alternative philosophy to atomism popularized by Descartes was \textit{corpuscularianism}. Built on ever divible corpuscles, contrary to atoms, its principles would be mainly used by alchemists like Newton who would later develop a corpuscular theory of light. Boyle would combine together ideas of both atomism or corpuscularianism leading to mechanical philosophy. The \Th{18} century has seen the development of engineering providing philosophical thought experiments with repeatable demonstration and a new point of view to explain the composition of matter. Lavoisier would greatly contribute to chemistry and atomism by publishing in 1789 a list of 33 chemical elements corresponding to what are now called \textit{atoms}~\cite{LAVOISIER1789}. In the early \Th{19} century Dalton would summarize the knowledge on composition of matter~\cite{DALTON1808}. In his atomic model, the atoms are ball-like constituants of the chemical elements. All atoms of a given element are identical, in size, mass, and other properties while the atoms of different element differ. He also considered that atoms cannot be divided into smaller particles, created nor destroyed and that they combine into chemical compounds. The essence of chemical reaction would then be the combination, separation or rearrangement of atoms. Soon after, Fraunhofer would invent the spectrometer and discover the spectral lines in the sunlight spectrum, as shown in Figure~\ref{fig:spectral-lines}~\cite{FRAUNHOFER1814}. These would later be linked to the absorption by chemical elements present in the solar atmosphere by Kirchhoff and Bunsen. The rise of atomic physics, chemistry and mathematical formalism would unravel the different atomic elements and ultimately, the \Th{20} century would see the very first sub-atomic particles.
	
	\subsubsection*{Discovery of the inner structure of the atom}
	\label{chapt2:sssec:atomstructure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=\plotwidth]{fig/chapt2/Thomson_Rutherford_atoms.pdf}
		\caption{\label{fig:Atom_models} Through the gold foil experiment Rutherford could show that most of the mass of atoms was contained in a positively charged nucleus and could then propose a more accurate atomic model than that of Thomson.}
	\end{figure}
	
	The negatively charged \textit{electron} would be the first to be discovered in 1897 by Thomson after 3 decades of research on cathode rays~\cite{THOMSON1897}. He proved that the electrification observed in an electroscope, as reported by Perrin~\cite{PERRIN1895}, was due to the rays themselves. Hence, they had to be composed of electrically charged particles. In 1900, Becquerel would show the \textit{beta rays} emitted by radium had the same charge over mass ratio as was measured by Thomson for cathode rays, pointing to eletrons as a constituant of atoms~\cite{BECQUEREL1900}. This discovery lead to Thomson's plum pudding atomic model in which electrons are embed into a uniform positively charged atom~\cite{THOMSON1904}. In 1907, Rutherford and Royds showed that \textit{alpha} particles were heluim ions~\cite{RUTHERFORD1908}. Indeed, once captured in a tube and subjected to an electric spark causing an electron avalanche, they could combine with two electrons to form a $^4$He.
	
	This discovery was directly followed by the constraint of the atom structure in between 1908 and 1913 through the Geigerâ€“Marsden gold foil experiments in which the deflection angle of alpha particles fired at a very thin gold foil was measured~\cite{GEIGER1908,GEIGER1909,GEIGER1910,GEIGER1913}. It highlighted that atoms were mainly empty with nearly all their mass contained into a tiny positively charged \textit{nucleus}. With these two observations, Rutherford could formulate the Rutherford planetary model of the atom in 1911~\cite{RUTHERFORD1911}, shown together with the Thomson plum pudding model in Figure~\ref{fig:Atom_models}. The link between atomic number and number of positive and negative charges contained into the atoms would fast be understood. Hence, the different kinds of element transmutations appeared to be purely nuclear processes making clear that the electromagnetic nature of chemical transformation could not possibly change nuclei. A new branch in physics appeared to exclusively study nuclei: \textit{nuclear physics}. By studying alpha emission and the product of their interaction with nitrogen gas, Rutherford reported in 1919 the very first nuclear reaction~\cite{RUTHERFORD1919}. It lead to the discovery that the hydrogen nucleus was composed of a single positively charged particle that was later baptised \textit{proton}~\cite{MASSON1921}. This idea came from 1815 Prout's hypothesis proposing that all atoms are composed of \textit{"protyles"} (i.e. hydrogen atoms)~\cite{PROUT1815,PROUT1816}. By using scintillation detectors, Rutherford could highlight typical hydrogen nuclei signature and understand that the impact of alpha particles with nitrogen would knock out an hydrogen nucleus and produce an oxygen 17, as explicited in Formula~\ref{eq:nuclear} and would then postulate that protons are building bricks of all elements.
	
	\begin{equation}
		\label{eq:nuclear}
		^{14}N + \alpha \rightarrow ^{17}O + p
	\end{equation}
	
	With this assumption and the discovery of \textit{isotopes} together with Aston, elements with identical atomic number but different masses, Rutherford would propose that all elements' nuclei but hydrogen's are composed of both charged particles, protons, and of chargeless particles, which he called \textit{neutrons}~\cite{RUTHERFORD1920,MASSON1921}. These neutral particles would help maintaining nuclei as one, as charged protons were likely to electrostatically repulse each other. He then introduced the idea of a new force, a \textit{nuclear} force. The first idea concerning neutrons was a bond state of protons and electrons as it was known that the beta decay, emitting electrons, was taking place in the nucleus. However, it was then shown that electrons being confined into the nucleus would hardly be possible due to Heisenberg's uncertainty principle. Finally, in 1932, following the discovery of a new neutral radiation, Chadwick could discover the neutron as an uncharged particle with a mass similar to that of the proton which would solve the nucleus puzzle~\cite{BOTHE1930,BOTHE1932,CURIE1932,CHADWICK1932,CHADWICK1933}.
	
	\subsubsection*{Development of the \acl{QED}}
	\label{chapt2:sssec:QED}
	
	Historically, the development of the quantum theory revolved around the question of emission and absorption of discrete amount of energy through light. Einstein used the initial intuition of Plank about the black-body radiation to develop in 1905 a model to explain the photoelectric effect in which light was described by discrete \textit{quanta} now called \textit{photons}~\cite{PLANK1900,EINSTEIN1905PHOTO}. For this model, Einstein introduced the concept of wave-particle duality as classical theory was not able to describe the phenomenon. With the new understanding of atoms and of their structure, classical theories also proved unable to explain atoms' stability. Indeed, using classical mechanics, electrons orbiting aroung a nucleus should radiate an energy proportionnal to their angular momentum and hence, loose energy through time and the spectrum of energy emission should then be continuous. However, it was known since the \Th{19} century and the discovery of spectral lines that the emission spectrum of material was discrete~\cite{FRAUNHOFER1814}.
	
	\begin{figure}[H]
		\begin{subfigure}{0.4\linewidth}
			\centering
			\includegraphics[height=5cm]{fig/chapt2/Bohr_atom_model.pdf}\\
			\caption{\label{fig:quantum-numbers:A}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height=6cm]{fig/chapt2/Sommerfeld_ellipses.pdf}
			\caption{\label{fig:quantum-numbers:B}}
		\end{subfigure}
		\begin{subfigure}{\linewidth}
			\centering
			\includegraphics[height=6cm]{fig/chapt2/Vector_model_of_orbital_angular_momentum.pdf}
			\caption{\label{fig:quantum-numbers:C}}
		\end{subfigure}
		\caption{\label{fig:quantum-numbers} Figure~\ref{fig:quantum-numbers:A}: The orbits in which the electron may travel according to the Borh model of the hydrogen atom. An electron jumps between orbits and is accompanied by an emitted or absorbed amount of electromagnetic energy ($h\nu$).The orbits radius increases as $n^2$. Figure~\ref{fig:quantum-numbers:B}: Elliptical orbits with the same energy and quantized angular momentum $l= 0, 1,...,n-1$ in the case $n=5$. Figure~\ref{fig:quantum-numbers:C}: Illustration of quantum mechanical orbital angular momentum. The cones and plane represent possible orientations of the angular momentum vector for $l=2$ and $m=-2,-1,0,1,2$.}
	\end{figure}
	
	In 1913 quantum physics would be introduced into the atomic model by Bohr to overcome the electron's energy loss due to orbiting radiation emission~\cite{BOHR1913}. Using the correspondence principle stating that for large enough numbers the quantum calculations should give the same results than the classical theory, he proposed the very first quantum model of the hydrogen atom explaining the line spectrum by introducing the \textit{principal quantum number} $n$ describing the electron \textit{shell}. The same year, Moseley would confirm Borh's model through the Moseley's law~\cite{MOSELEY1913}. Debye and then Sommerfeld would extend it by introducing the quantization of the angular momentum~\cite{SOMMERFELD1916}. The quantization the z-component of the angular momentum would lead to the \textit{second} and \textit{third quantum numbers}, or \textit{azimuthal} and \textit{magnetic quantum number}, $l$ and $m$. The second defines the orbital angular momentum of the electrons on their shells and hence, the shape of the orbital, while the third the available orbital on the subshell for each electron as shown in Figure~\ref{fig:quantum-numbers}.
	
	\begin{figure}[H]
		\begin{subfigure}{\linewidth}
			\centering
			\includegraphics[height=5cm]{fig/chapt2/ZeemanEffectIllus.png}
			\caption{\label{fig:spin:A}}
		\end{subfigure}
		\begin{subfigure}{\linewidth}
			\centering
			\includegraphics[width = \plotwidth]{fig/chapt2/Stern-Gerlach_experiment.pdf}
			\caption{\label{fig:spin:B}}
		\end{subfigure}
		\caption{\label{fig:spin} Figure~\ref{fig:spin:A}: The spectral lines of mercury vapor lamp anomalous Zeeman effect without magnetic field (A) and with magnetic field (B - transverse Zeeman effect \& C - longitudinal Zeeman effect). Figure~\ref{fig:spin:B}: Sternâ€“Gerlach experiment: Silver atoms travelling through an inhomogeneous magnetic field, and being deflected up or down depending on their spin.}
	\end{figure}
	
	Nevertheless, although the model was not only limited to spherical orbitals anymore, making the atom more realistic, the Zeeman effect couldn't be completely explained by just using $n$, $l$ and $m$~\cite{ZEEMAN431897,ZEEMAN441897I,ZEEMAN441897II,ZEEMAN451898} nor could the result of the Stern-Gerlach experiment~\cite{GERLACH1922}. Both experiments are shown in Figure~\ref{fig:spin}. A solution would be brought after Pauli in 1925 proposed together with his exclusion principle the idea of a new quantum degree of freedom in order to resolve the apparent problem~\cite{PAULI1925I,PAULI1925II}. This degree of freedom would be interpreted as an intrinsic angular momentum vector associated to the particle itself, not to the orbital~\cite{UHLENBECK1926}, and associated to a new quantic number $s$, the \textit{spin} projection quantum number explaining the lift of degeneracy to an even number of energy levels~\cite{PAULI1927}. The new quantum number helped in theorizing the neutron as a neutral particle rather than a bond state of proton and electron confined in the nucleus itself.
	
	The introduction of the \textit{spin} happened one year after another attempt of improvement of the theory was made by De Broglie in his Ph.D. thesis~\cite{DEBROGLIE1924}. The original formulation of the quantum theory only considered photons as energy quanta behaving as both \textit{waves} and \textit{particles}. De Broglie proposed that \textit{all} matter are described by waves and that their momentum is proportional to the oscillation of quantized electromagnetic field oscillators. This interpretation was able to reproduce the previous version of the quantum energy levels by showing that the quantum condition involves an integer multiple of $2\pi$, as shown by Formula~\ref{eq:matterwave}.
	
	\begin{equation}
		\label{eq:matterwave}
		p = \hbar k \Leftrightarrow \int p dx = \hbar\int k dx = 2\pi\hbar n
	\end{equation}
	
	Although the intuition of De Broglie about the wave-particle duality of all matter was a step in the right direction, his interpretation was semiclassical and it is in 1926 that the first fully quantum mechanical wave-equation would be introduced by SchrÃ¶dinger to describe electron-like particles, reproducing the previous semiclassical formulation without inconsistencies~\cite{SCHRODINGER1926}. This complex equation describes the evolution of the wave function $\Psi$ of the quantum system, defined by it's position vector $\mathbf{r}$ and time $t$ as an energy conservation law, in which the hamiltonian of the system $\hat{H}$ is explicit, by solving the Equation~\ref{eq:schrodinger}.
	
	\begin{equation}
		\label{eq:schrodinger}
		i\hbar \frac{\partial}{\partial t} \vert \Psi(\mathbf{r},t)\rangle  = \hat{H} \vert \Psi(\mathbf{r},t)\rangle
	\end{equation}
	
	The spin would then be included into SchrÃ¶dinger equation by Pauli to take into account the interaction with an external magnetic field, as shown in Equation~\ref{eq:pauli} in which the Hamiltonian operator is a $2 \times 2$ matrix operator due to the Pauli matrices~\cite{PAULI1927}. $\mathbf{A}$ is the vector potential and $\phi$ is the scalar electric potential.
	
	\begin{equation}
		\label{eq:pauli}
		i\hbar \frac{\partial}{\partial t} \vert\Psi\rangle  =  \left[\frac{1}{2m}(\mathbf{\sigma}\cdot(\mathbf{p}-q\mathbf{A})^2+q\phi)\right]\vert\Psi\rangle
	\end{equation}
	
	Later in 1927, Dirac would go further in his paper about emission and absorption of radiation by proposing a second quantization not only of the physical process at play but also of the electromagnetic field~\cite{DIRAC1927}. His equation provided the ingredients to the first formulation of \textit{\acf{QED}} and the description of photon emission by electrons dropping into a lower energy state in which the final number of particles is different than the initial one. Nevertheless, in order to properly treat electromagnetism, the incorporation of the special relativity developed by Einstein was necessary. Derived in 1928, the Dirac equation, shown as Equation~\ref{eq:dirac}, similarly to SchrÃ¶dinger equation, is a single-particle equation but it incorporates special relativity in addition to quantum mechanics rules~\cite{DIRAC1928}.
	
	\begin{equation}
		\label{eq:dirac}
		i\hbar \gamma^\mu\partial_\mu\psi - mc\psi = 0
	\end{equation}
	
	It features the $4 \times 4$ gamma matrices $\gamma^\mu$ built using $2 \times 2$ Pauli matrices and the unitary matrix, the 4-gradient $\partial_\mu$, the rest mass $m$ of any half integer spin massive particle described by the wave function $\psi(x,t)$, also called a Dirac spinor, and the speed of light $c$. In addition to perfectly reproduce the results obtained with quantum mechanics so far, it also provided \textit{negative-energy solutions} that would later be interpreted as a new form of matter, \textit{antimatter}~\cite{OPPENHEIMER1930I,DIRAC1931}. In the non-relativistic limit, the Dirac equation gives a theoretical justification to the Pauli equation that was phenomenologically constructed to account for the spin.
	
	The successes of the QED was soon followed with theoretical problems as computations of any physical process involving photons and charged particles were shown to be only reliable at the first order of the \textit{perturbation theory}~\cite{OPPENHEIMER1930II}. At higher order of the theory, divergent contributions were appearing giving nonsensical results. Only two effects were contributing to these infinities.
	
	\begin{itemize}
		\item The self-energy of the electron (or positron), the energy that the particle has due to its own interaction with its environment.
		\item The vacuum polarization, virtual electronâ€“positron pairs produced by a background electromagnetic field in the vacuum which is not an "empty" space. These virtual pairs affect the charge and current distributions generated by the original electromagnetic field.
	\end{itemize}
	
	Solving this apparent problem was done by carefully defining the concepts of each observables, for example mass or charge, as these quantities are understood within the context of a non-interacting field equation. From the experimental point of view, they are abstractions as what is measured are "renormalized observables" shifted from their "bare" value by the interaction taking place in the measuring process. The infinities needed to be connected to corrections of mass and charge as those are fixed to finite values by experiment. This was the intuition of Bethe in 1947 who successfully computed the effect of such \textit{renormalization} in the non-relativistic case~\cite{BETHE1947}. Fully covariant formulations of QED including renormalization was achieved by 1949 by Tomonaga, Schwinger, Feynman and Dyson~\cite{DYSON1949}. With the resolution of infinities, QED had mostly reached its final form, being still today the most accurate physical theory, and would serve as a model to build all other quantum field theories.
	
	\subsubsection*{Development of the quark model and \acl{QCD}}
	\label{chapt2:sssec:quark}
	
	To explain the nuclear force that holds \textit{nucleons} (protons and neutrons) together, Yukawa proposed in 1934 the existence of a force carrier called \textit{meson} due to it's predicted mass in the range in between the electron and nucleon masses~\cite{YUKAWA1935}. Discovered in 1936 by Anderson and Neddermeyer~\cite{ANDERSON1936,NEDDERMEYER1937}, and confirmed using bubble chambers in 1937 by Street and Stevenson~\cite{STREET1937}, a first meson candidate was observed in the decay products of cosmic rays. Assuming it had the same electric charge as electrons and protons, this particle was observed to have a curvature due to magnetic field that was sharper than protons but smoother than electrons resulting in a mass in between the two. But its properties were not compatible with Yukawa's theory, which was emphasized by the discovery of a new candidate in 1947, again in cosmic ray products using photographic emulsions~\cite{LATTES1947I,LATTES1947II,LATTES1947III}.
	
	This new candidate, although it had a similar mass than the already believed \textit{meson}, would rather decay into it. For distinction, the first candidate would then be renamed "\textit{mu meson}" when the second would be the "\textit{pi meson}". The \textit{mu meson} was behaving like a heavy electron and didn't participate in the strong interaction whereas the pion was believed to be the carrier of the nuclear interaction. This lead to classify the \textit{mu} in a new category of particles called \textit{leptons} together with the electron that shared similar properties and \textit{the} neutrino, and be renamed \textit{muon}. The \textit{pi meson} was finally found to be a triplet of particles: a positively charged, a negatively charged, and a neutral particle. The neutral \textit{pi meson} has been more difficult to identify as it wouldn't leave tracks on emulsions nor on bubble chambers and needed to be studied via it's decay products. It was ultimately identified in University of California's cyclotron in 1950 through the observation of its decay into 2 photons.
	
	Also discovered in 1947 but in cloud chamber photographs, the \textit{K meson} as also been an important step towards the establishment of the \acl{SM}. A triplet of particle, 2 charged and a neutral, with a mass roughly half that of a proton, were reported. These particles were baptised \textit{K meson} in contrast to the "light" \textit{pi} and \textit{mu} "L-mesons". The particularity of the \textit{K} were there very slow decays with a typical lifetime of the order of \Ord{-10}\si{s} much greater than the \Ord{-23}\si{s} of \textit{pi}-proton reactions. The concept of \textit{strangeness}, a new quantum number was then introduced by Pais as an attempt to explain this phenomenom as \textit{strange} particles appeared as a pair production of a strange and anti-strange particle.
	
	With the development of synchrotrons, the particle \textit{zoo} would grow to several dozens during the 1950s as higher energies were reachable through acceleration. In 1961, a first classification system, called Eightfold Way, was proposed by Gell-Mann and finding its roots in the Gell-Mann--Nishijima formula, which relates the electric charge $Q$, the third component of the isospin $I_3$, the \textit{baryon} number $B$ and the strangeness $S$, as explicited in Formula~\ref{eq:NNG}. The isospin was a quantum number introduced in 1932 to explain symmetries of the newly discovered neutron using representation theory of SU(2). The baryon number, was introduced by Nishijima as a quantum number for baryons, i.e. particles of the same family as nucleons. The mesons were classified in an octet and baryons of spin $\pm\frac{1}{2}$ and $\pm\frac{3}{2}$ were respectively classified into an octet and a decuplet, as shown in Figure~\ref{fig:Eightfold}. To complete the baryon decuplet, Gell-Mann predicted the existance of baryon $\Omega^-$ which would later be discovered in 1964.
	
	\begin{equation}
		\label{eq:NNG}
		Q = I_3 + \frac{1}{2}(B+S)
	\end{equation}
	
	\begin{figure}[H]
		\begin{subfigure}{\linewidth}
			\centering
			\includegraphics[width=0.4\linewidth]{fig/chapt2/Meson_octet.png}\\
			\caption{\label{fig:Eightfold:A}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[width=0.8\linewidth]{fig/chapt2/Baryon_octet.png}
			\caption{\label{fig:Eightfold:B}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[width=0.8\linewidth]{fig/chapt2/Baryon_decuplet.png}
			\caption{\label{fig:Eightfold:C}}
		\end{subfigure}
		\caption{\label{fig:Eightfold} Figure~\ref{fig:Eightfold:A}: Meson octet. Figure~\ref{fig:Eightfold:B}: Baryon octet. Figure~\ref{fig:Eightfold:C}: Baryon decuplet.}
	\end{figure}
	
	Strong of this classification using an SU(3) flavor symmetry, Gell-Mann, and independently Zweig, would propose a full theoretical model in which \textit{hadrons} (strongly interacting particles, i.e. mesons and baryons) were not elementary particles anymore. They would rather be composed with 3 flavors of particles called \textit{quarks} and there anti-particles. The 3 flavors were called \textit{up}, \textit{down} and \textit{strange}. \textit{Up} and \textit{down} would be used to explain the nucleons and non-strange mesons, while \textit{strange} would come into the composition of hadrons showing strangeness. \textit{Up} and \textit{down} flavors would be discovered in 1968 thanks to the deep inelastic scattering experiments conducted at the \acf{SLAC}, and \textit{strange} could only be indirectly validated eventhough it provided a robust explanation to \textit{kaon} (K) and \textit{pion} ($\pi$). However, in the decade following the Gell-Mann-Zweig quark model proposition, several improvement to the model were brought, first by Glashow and Bjorken the same year that predicted the existence of a fourth quark flavor, the \textit{charm}, that would equalize the then known number of quarks and leptons and finally in 1973 by Kobayashi and Maskawa that would increase the number of quarks to 6 to explain the experimental observation of CP violation. These two quarks would been refered to as \textit{top} and \textit{bottom} for the first time in 1975. It's only after these additions to the quark model that finally the \textit{charm} would be discovered in 1974 at both SLAC and \acf{BNL}. A meson where the \textit{charm} was bond with an \textit{anti-charm}, called $J/\psi$, would help convince the physics community of the validity of the model. The \textit{top} would be discovered soon after in 1977 in Fermilab and indicate the existence of the \textit{bottom} that would resist to discovery until Fermilab's experiments CDF and D$\emptyset$ in 1995 due its very large mass and the energy needed to produce it.
	
	As remarked by Struminsky, the original quark model proposal composed of 3 quarks should possess an additional quantum number due to mesons such as $\Omega^-$ or $\Delta^{++}$. Indeed, these mesons are composed of 3 identical quarks, respectively 3 \textit{strange} and \textit{up} quark, with parallel spins, which should be forbidden by the exclusion principle. Independentle, Greenberg and Han-Nambu proposed an additional SU(3) degree of freedom possessed by the quarks, that would later be refered to as \textit{color charge gauge}, that could interact through \textit{gluons}, the gauge boson octet corresponding to this degree of freedom. Nevertheless, as observing free quarks proved to be impossible, two visions of the quarks were argued mainly due to the failures to observe these particles free to prove their existence. On one side, Gell-Mann proposed to see quarks as mathematical construct instead of real particles, as they are always confined, implying that quantum field theory would not describe entirely the strong interaction. Opposed to this vision, Feynman on the contrary argued that quarks were real particles, that he would call \textit{partons}, that should be described as all other particles by a distribution of position and momentum. The implications of quarks as point-like particles would be verified at SLAC and the concept of \textit{color} would be added to the quark model in 1973 by Fritzsch and Leutwyler together with Gell-Mann to propose a description of the strong interaction through the theory of \acf{QCD}. The discovery the same year of asymptotic freedom within the QCD by Groos, Politzer and Wilczek, allowed for very precise predictions thanks to the perturbation theory. Nowadays, the confinement of quarks is studied in experiments such as ALICE, through exploration of the quark-gluon plasma.
	
	\subsubsection*{The Weak interaction, spontaneous symmetry breaking, the Higgs mechanism and the Electroweak unification}
	\label{chapt2:sssec:HiggsEW}
	
	The weak interaction is the process that causes radioactive decays. Thanks to the neutron discovery, Fermi could explain in 1934 the beta radiations through the beta decay process in which the neutron decays into a proton by emitting an electron. Though the missing energy observed during this process triggered a huge debate about the apparent non conservation of energy, momentum and spin of the process, Fermi, as Pauli before him, proposed that the missing energy was due to a neutral not yet discovered particle that would then be baptised \textit{neutrino}. The impossibility to detect such a particle would leave some members of the scientific community sceptical, but hints of energy conservation and of the existence of the neutrino were provided by measuring the energy spectrum of electrons emitted through beta decay, as there was a strict limit on their energy. It's only 30 years later in 1953 that it would be discovered by the team of Cowan and Reines using the principle of inverse beta decay described through Formula~\ref{eq:invbeta}. The experiment consisted in placing water tanks sandwiched in between liquid scintillators near a nuclear reactor with an estimated neutrino flux of \Sci{5}{13}\siflux. However, in order to explain the absence of some reactions in the experiment of Cowan and Reines, and constraint the beta decay theory of Fermi and extend it to the case of the muon, Konopinski and Mahmoud proposed in 1953 that the muon decay would eject a particle similar to the neutrino and thus predicted the existence of a muon neutrino that would be different than the one involved in the beta decay, related to the electron. With this, the idea of lepton number would arise. The muon neutrino would successfully be detected in 1962 by lederman, Schwartz and Steinberger.
	
	\begin{equation}
		\label{eq:invbeta}
		\overline{\nu} + p \rightarrow n + e^+
	\end{equation}
	
	The theory could not be valid though as the probability of interaction, called cross-section, would have been increasing without bond with the square of the energy. Fermi assumed in a two vector current coupling but Lee and Yang noted that an axial current could appear and would violate parity. The experiment of Wu in 1956 would confirm the parity violation and Gamov and Teller would try to account for it by describing Fermi's interaction through allowed (parity-violating) and superallowed (parity-conserving) decays. But the success of QED as a quantum field theory would spark the development of such a theory to describe the weak interaction.
	
	As previously discussed, the great success of QED was built on an underlying symmetry, interpreted as a gauge invariance so that the effect of the force is the same in all space-time coordinates, and of the possibility to renormalize it in order to absorb the infinites. Independently in 1958, Glashow, and Salam and Ward used 1957 Schwinger ideas about vector intermediary for the decay processes, could find a way to unite both the electromagnetic and weak interaction into a gauge theory involving 4 gauge bosons, 3 of which were massive and carried out the weak interaction and a massless boson carrying the electromagnetic interaction. Among the 3 massive bosons, 2 were charged and 1 was neutral, similarly to the previously theorized \textit{pi meson} vector of the Yukawa model and all have a mass much greater than nucleons and thus a very short life time implying a finite very short range contrary to the contact interaction originally proposed by Fermi.
	
	Breakthrough in other fields of physics contributed in giving theoretical support and interpretation to the unified electroweak theory. The stepping stone would be the use of spontaneous symmetry breaking that was inspired to Nambu at the end of the 1950s following the development of the \acf{BCS} superconductivity mechanism in 1957. Cooper had shown that BCS pairs, pairs of electrons bound together at low temperature, could have lower energy than the Fermi energy and where responsible for superconductivity. This lead to the discovery of Goldstone-Nambu bosons as a result of the spontaneous breaking of the chiral symmetry in a theory describing nucleons and mesons developped by Nambu and Jona-Lasinio in 1961, and now understood as a low-ebergy approximation of QCD. Simmilarly to mechanism of energy gap appearance in superconductivity, the nucleon mass is suggested to the result of a self-energy of a fermion field and is studied through a four-fermion interaction in which, as a consequence of the symmetry, bound states of nucleon-antinucleon pairs appear and can be regarded as virtual pions. Though the symmetry is maintained in the equations, the ground state is not preserved. Goldstone would later the same year show that the bound states corresponds to spinless bosons with zero mass.
	
	Although the model in itself didn't revolutionize particle physics, spontaneous symmetry breaking would be generalized to quantum field theories. As all fundamental interactions are described using gauge theories based on underlying symmetries, processes such as the chiral symmetry breaking would be introduced soon after the publication of Nambu and Jona-Lasinio. In 1962, Anderson, following an idea of Schwinger who suggested that zero-mass vector bosons were not necessarily required to describe the conservation of baryons contrary to the bosons emerging from chiral symmetry breaking, discussed the implications of spontaneous symmetry breaking in particles physics. A model was finally independently built in 1964 by Brout and Englert, Higgs, and Guralnik, Hagen, and Kibble, who discovered that combining an additional field into a gauge theory in order to break the symmetry, the resulting gauge bosons acquire a nonzero mass. Moreover, Higgs stated that this implied the existence of at least one new massive, i.e. self-interacting, scalar boson, that are now known as \textit{Higgs bosons} corresponding to this additional field. The Higgs mechanism today specifically refers to the process through which the gauge bosons of the weak interaction acquire mass. In 1968, Weinberg could point to the Higgs mechanism to integrate a Higgs field into a new version of the electroweak theory in which the spontaneous symmetry breaking mechanism of the Higgs field would explicitely explain the masses of the weak interaction gauge bosons and the zero-mass of photons.
	
	\subsection{Construction and test of the model}
	\label{chapt2:ssec:model}
	
	The Standard Model of particle physics was built in the middle of the 1970s after the experimental confirmation of the existence of quarks. It is based on the assembly of the models previously introduced and describing the fondamental interactions, except for gravitation, and their gauge bosons as well as the way elementary "matter" particles interact with the fields associated with these force carriers. In this sense, the development of QED and the unification of the electroweak interaction, of the Yukawa interaction and of QCD, and of the Higg mechanism made it possible to explain most of contemporary physics.
	
	In the SM, "matter" particles, are described by 12 fermion fields of spin $\frac{1}{2}$ obeying the Fermi-Dirac statistics, i.e. subjected to the Pauli exclusion principle. To each fermion is associated its corresponding antiparticle. The fermions are classified according to the way they interact and, thus, according to the charges they carry. 6 of them are classified as quarks ($u$, $d$, $c$, $s$, $t$, and $b$) and are subjected to all interactions and the 6 others as leptons ($e^-$, $\mu^-$, $\tau^-$, $\nu_e$, $\nu_\mu$, and $\nu_\tau$). Leptons are not subjected to the strong interaction and among them, the 3 neutrinos only interact weakly as they are neutral particles, which explains why they are so difficult to detect. The gauge boson fields are the gluons $g$ for the strong interaction, the photon $\gamma$ for the electromagnetic interaction and the weak bosons $W^+$, $W^-$, and $Z^0$ for the weak interaction. Finally, the Higgs field $H^0$ is responsible, through the spontaneous symmetry breaking, of the mixing of the massless electroweak boson fields $W_1$, $W_2$, $W_3$, and $B$ leading to the observable states $\gamma$, $W^+$, $W^-$, and $Z^0$ that can gain mass while interacting with the Higgs field. This picture of the SM is summarized through Figure~\ref{fig:SM} where the antifermions are not shown.
	
	When the model was first finalized, the existence of the weak gauge bosons, of the charm, of the third quark generation composed of top and bottom quarks to explain the observed CP violation was not proven but the predictions were measured with good precision in the years following. First, the charm quark would be discovered in 1974, followed by the bottom quark in 1977. The weak bosons would be discovered during the next decade in 1983. The top quark would resist until 1995 due to its very large mass but would offer the last piece of the elementary QCD particles. The very last predicted elementary particle of the model that was not observed yet would prove to be very difficult to observe. the Higgs boson needed the start of the LHC to finaly be oberved in 2012. A few years more of tests were necessary to measure its properties to confirm the observation of a scalar boson compatible with the predicted Higgs boson $H^0$. Eventhough only quark-antiquark (mesons) and 3 quark states (baryons) were observed, exotic hadrons were not forbidden by QCD and no limit of quark is imposed by the theory. Moreover, gluons could form bond states by themselves and with quarks. These two types of states are called \textit{glueballs} and \textit{hybrid hadrons}. For decades, experiments have been conducted without confirmation of such possible states existing. Nevertheless, in 2014, tetraquarks were observed by LHCb, one of LHC's main experiments, and in 2015, the same experiment reported the discovery of pentaquarks making the SM one of the best tested theories of physics.
	
	\begin{figure}[H]
		\centering
		\hspace*{-0.1\linewidth}
		\includegraphics[width=1.2\linewidth]{fig/chapt2/Standard_Model_Of_Particle_Physics.png}
		\caption{\label{fig:SM} The elementary particles of the Standard Model are shown along with their names and properties. Their interactions with the strong, weak and electromagnetic forces have been explicited using color squares. In the left column, the scalar higgs boson is depicted, while the central is focused on the matter particles, the fermions, and the right on the force carriers, the gauge bosons. The role of the Higgs boson in electroweak symmetry breaking is highlighted, and the corresponding way properties of the various particles differ in the (high-energy) symmetric phase (top) and the (low-energy) broken-symmetry phase (bottom) are shown.}
	\end{figure}
	
	\subsection{Investigating the TeV scale}
	\label{chapt2:ssec:TeV}
	
	Even though the SM is a well tested theory, several hints of physics going beyond its scope have been observed. First of all, gravity is not explained through this model and huge difficulties are encountered when trying to include gravitation. The strength of gravitational interaction is expected to be negligible at the scale of elementary particles, nevertheless, adding gravitation in the perspective of developing a \textit{"theory of everything"} leads to divergent integrals that could not be fixed through renormalization.
	
	Moreover, the SM considers neutrinos to be massless but it was shown in the late 1960s by the Homestake experiment that the flux of solar neutrinos (i.e. $\nu_e$) measured didn't match the predicted values due to neutrino oscillations, confirmed in the early 2000s by the Sudbury Neutrino Observatory. This oscillation implies that neutrinos that can be observed are a superposition of massive neutrino states. The research on neutrino oscillation is already quite advanced with experiments looking at atmospheric, reactor or beam neutrinos in order to determine the elements of the mixing matrix similar to the CKM matrix describing the mixing of quarks. Nevertheless, no answer to the origin of neutrino mass is provided.
	
	Another intriguing fact is that the universe is dominated by matter. However, the SM predicted that matter and antimatter should have been created in equal amounts and no mechanism is able to explain this matter-antimatter asymmetry. Although this asymmetry is seen from the visible universe, it may be possible that other unknown regions of the Universe are dominated by antimatter. Another possibility to explain the apparent asymmetry would be the existence of a electric dipole in any fundamental particle that would permit matter and antimatter particles to decay at different rates.
	
	The discrepancy of velocity dispersion of stars in galaxies with respect to the visible mass they contain is known since the end of the \Th{19} century where Kelvin proposed that this problem could be solved if a \textit{"great majority of [the stars] would be dark bodies"}. Throughout the \Th{20} century, physicists like Kapteyn, Zwicky, showed the first hints of a \textit{"dark matter"} by studying star velocities and galactic clusters, followed by robust measurements of galaxy rotation curves by Babcock which suggested that the mass-to-luminosity ratio was different from what would be expected from watching the visible light. Later in the 1970s, Rubin and Ford from direct light observations and Rogstad and Shostak from radio measurements showed that the radial velocity of visible objects in galaxies was increasing with increasing distance to the center of the galaxy. Finally observation of lensing effect by galaxy clusters, temperature distribution of hot gas in galaxies and clusters, and the anisotropies in the \acf{CMB} kept on pointing to a \textit{"dark matter"}. From all the data accumulated, the visible matter would only account to no more than 5\% of the total content on the visible universe. Alternative theories have tried to investigate modified versions of the General Relativity as this theory is only well tested at the scale of the solar system but is not sufficiently tested on wider ranges or even theories in which gravitation is not a fundamental force but rather an emergent one, but so far, such theories have difficulties to reproduce all the experimental observations as easily as through dark matter.
	
	A possible theory to offer dark matter candidates would be \acl{SUSY} which proposes a relationship in between bosons and fermions. In this model, each elementary particle, through a spontaneous spacetime symmetry breaking mechanism would have a \textit{super partner} from the other family of particles. On top of providing heavy dark matter candidates, supersymmetry could also help solving the \textit{Hierarchy problem}, the very large scale difference in between the weak interaction and gravity, although, as mentioned before, in the case gravity is found not to be a fundamental force, this problem would automatically fade.\\
	
	All these different aspects of physics beyond the Standard Model of particle physics and the Standard model itself can be tested through the use of very energetic and intense hadron and ion colliders. The LHC at CERN is a perfect tool to seek answers to these open questions except maybe for the gravity as gravity is extremely weak at particles level. For example, one of LHCb experiment's goal is to investigate CP-violation and thus baryonic asymmetry. In 2017, the collaboration has announced to have so far a \Sig{3.3} statistical significance over a CP-violation through the study of the decays of $\Lambda^0_b$ and $\overline{\Lambda^0_b}$ into a proton (or antiproton) and 3 pions. Many analysis teams are also working hard on supersymmetry both in ATLAS and CMS collaborations, the two multipurpose experiments of LHC, even though no evidence of a supersymmetrical theory was seen, the few hint having the tendency to confirm the standard model. These experiments also have the possibility to investigate ways to explain Majorana neutrino mass through Yukawa interactions of scalar particles.
	
	The higher the center-of-mass energy, the smaller details the experiments will be able to see, the heavier the potential particle creation barrier will be, the stronger the cross-section of certain rare decay channels will be. As a comparison, with collisions happening at \SI{14}{TeV}, the LHC is approximately 2 orders of magnitude more sensitive to the Higgs than the Tevatron was with its already very powerful \SI{2}{TeV}. All these advantages eventually lead to new discoveries and deeper understanding of the models describing our Universe. But the LHC only is a step forward to gather more precise tests of the Standard Model and new knowledge about the physics beyond it. A successful physics campaign will probably serve to justify the building of new accelerators with even greater discovery potential like for example the \acf{FCC} that would push even further the study of the unanswered questions of contemporary physics.

\section{The \acl{LHC} \& the \acl{CMS}}
\label{chapt2:sec:LHC-CMS}

	Throughout its history, CERN has played a leading role in high energy particle physics. Large regional facilities such as CERN were thought after the second world war in an attempt to increase international scientific collaboration and allows scientists to share the forever increasing costs of experiment facilties required due to the need for increasing the energy in the center of mass to deeper probe matter. The construction of the first accelerators at the end of the 50s, the \acf{SC} and the \acf{PS}, was directly followed by the first observation of antinuclei in 1965~\cite{MASSAM1965}. Strong from the experience of the \acf{ISR}, the very first proton-proton collider that showed hints that protons are not elementary particles, the \acf{SPS} was built in the 70s to investigate the structure of protons, the preference for matter over antimatter, the state of matter in the early universe or exotic particles, and lead to the discovery in 1983 of the W and Z bosons~\cite{UA1W1983,UA2W1983,UA1Z1983,UA2Z1983}. These newly discovered particles and the electroweak intereaction would then be studied in details by the \acf{LEP} collider that will help to prove in 1989 that there only are three generations of elementary particles~\cite{ALEPH1989}. The LEP would then be dismantled in 2000 to allow for the LHC to be constructed in the existing tunnel.

	\subsection{LHC, the most powerful particle accelerator}
	\label{chapt2:ssec:LHC}
	
	The LHC has always been considered as an option to the future of CERN. At the moment of the construction of the LEP beneath the border between France and Switzerland, the tunnel was built in order to accomodate what would be a \acl{LHC} with a dipole field of \SI{10}{T} and a beam energy in between 8 and \SI{9}{TeV}~\cite{ANNUALREPORT1984} directly followed in 1985 with the creation of a 'Working Group on the Scientific and Technological Future of CERN' to investigate such a collider~\cite{ANNUALREPORT1985}. The decision was finally taken almost 10 years later, in 1994, to construct the LHC in the LEP tunnel~\cite{ANNUALREPORT1994} and the approval of the 4 main experiments that would take place at the 4 interaction points would come in 1997~\cite{ANNUALREPORT1997} and 1998~\cite{ANNUALREPORT1998}:
	
	\begin{itemize}
		\item[â€¢] ALICE~\cite{ALICELOI} has been designed in the purpose of studying quark-gluon plasma that is believed to have been a state of matter that existed in the very first moment of the universe.
		\item[â€¢] ATLAS~\cite{ATLASLOI} and CMS~\cite{CMSLOI} are general purpose experiements that have been designed with the goal of continuing the exploration of the Standard Model and investigate new physics.
		\item[â€¢] LHCb~\cite{LHCBLOI} has been designed to investigate the preference of matter over antimatter in the universe through the CP violation.
	\end{itemize}

	\begin{figure}[H]
		\centering
		\includegraphics[width=\linewidth]{fig/chapt2/CERN_Accelerator_Complex.png}
		\caption{\label{fig:CERNComplex} CERN accelerator complex.}
	\end{figure}
	
	These large scale experiments, as well as the full CERN accelerator complex, are displayed on Figure~\ref{fig:CERNComplex}. The LHC is a \SI{27}{km} long hadron collider and the most powerful accelerator used for particle physics since 2008~\cite{LHC2008}. The LHC was originally designed to collide protons at a center-of-mass energy of \SI{14}{TeV} and luminosity of $10^{34}$ \si{cm^{-2}s^{-1}}, as well as $Pb$ ions at a center-of-mass energy of \SI{2.8}{TeV/A} with a peak luminosity of $10^{27}$ \si{cm^{-2}s^{-1}}. Run 1 of LHC, when the center-of-mass energy only was half of the nominal LHC energy, was enough for both CMS and ATLAS to discover the Higgs boson~\cite{HIGGS2015} and for LHCb to discover pentaquarks~\cite{PENTAQUARK2015} and confirm the existance of tetraquarks~\cite{TETRAQUARK2017}. Nevertheless, after the \acf{LS3} (2024-2026), the accelerator will be in the so called \acl{HL-LHC} configuration~\cite{HLLHC2017}, increasing its instantaneous luminosity to $10^{35}$ \si{cm^{-2}s^{-1}} for $pp$ collisions and to $4.5\times 10^{27}$ \si{cm^{-2}s^{-1}}, boosting the discovery potential of the LHC. The HL-LHC phase should last at least another 10 years depending on the breakthrough this machine would lead to. Already a new accelerating device, the FCC, as been proposed to prepare the future of high energy physics after the LHC.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.45\linewidth]{fig/chapt2/CERN-accelerators.jpg}
		\caption{\label{fig:CERNAccelerators} Pictures of the different accelerators. From top to bottom: first the LINAC 2 and the $Pb$ source of LINAC 3. Then the Booster and the LEIR. Finally, the PS, the SPS and the LHC.}
	\end{figure}
	
	The LHC is the last of a long series of accelerating devices. Before being accelerated by the LHC, the particles need to pass through different acceleration stages. All these acceleration stages are visible on Figure~\ref{fig:CERNComplex} and pictures of the accelerators are shown in Figure~\ref{fig:CERNAccelerators}.\\
	
	The story of accelerated protons at CERN starts with a bottle of hydrogen gas injected into the source chamber of the linear particle accelerator \textit{LINAC 2} 2 in which a strong electric field strips the electron off the hygroden molecules only to keep their nuclei, the protons. The cylindrical conductors, alternatively positively or negatively charged by radiofrequency cavities, accelerate protons by pushing them from behing and pulling them from the front and ultimately give them an energy of \SI{50}{MeV}, increasing their mass by 5\% in the process.
	
	When exiting the LINAC 2, the protons are divided into 4 bunches and injected into the 4 superimposed synchrotron rings of the \textit{Booster} where they are then accelerated to reach an energy of \SI{1.4}{GeV} before being injected into the \textit{PS}. Before the Booster was operational in 1972, the protons were directly injected into the PS from the LINAC 2 but the low injection energy limited the amount of protons that could be accelerated at once by the PS. With the Booster, the PS accepts approximately 100 times more particles.
	
	The 4 proton bunches are thus sent as one to the PS where their energy eventually reaches \SI{26}{GeV}. Since the 70s, the main goal of this \SI{628}{m} circumference synchrotron has been to supply other machines with accelerated particles. Nowadays, not only the PS accelerates protons, it also accelerates heavy ions from the \textit{\acf{LEIR}}. Indeed, the LHC experiments are not only designed to study $pp$-collinsions but also $Pb$-collisions. Lead is first injected into the dedicated linear collider \textit{LINAC 3}, that accelerate the ions using the same principle than LINAC 2. Electrons are striped off the lead ions all along the acceleration process and eventually, only bare nuclei are injected in the LEIR whose goal is to transform the long ion pulses received into short dense bunches for LHC. Ions injected and stored in the PS were aceelerated by the LEIR from \SI{4.2}{MeV} to \SI{72}{MeV}.
	
	Directly following the PS, is finally the last acceleration stage before the LHC, the \SI{7}{km} long \textit{SPS}. The SPS accelerates the protons to \SI{450}{GeV} and inject proton in both LHC accelerator rings that will increase their energy up to \SI{7}{TeV}. When the LHC runs with heavy lead ions for ALICE and LHCb, ions are injected and accelerated to reach the energy of \SI{2.8}{TeV/A}.
	
	\begin{figure}[H]
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/LHC-dipole.png}
			\caption{\label{fig:LHCDipole:A}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/LHC-dipole-field.jpg}
			\caption{\label{fig:LHCDipole:B}}
		\end{subfigure}
		\caption{\label{fig:LHCDipole} Figure~\ref{fig:LHCDipole:A}: schematics of the LHC cryodipoles. 1: Superconducting Coils, 2: Beam pipe, 3: Heat exchanger Pipe, 4: Helium-II Vessel, 5: Superconducting Bus-bar, 6: Iron Yoke, 7: Non-Magnetic Collars, 8: Vacuum Vessel, 9: Radiation Screen, 10: Thermal Shield, 11: Auxiliary Bus-bar Tube, 12: Instrumentation Feed Throughs, 13: Protection Diode, 14: Quadrupole Bus-bars, 15: Spool Piece Bus-bars. Figure~\ref{fig:LHCDipole:B}: magnetic field and resulting motion force applied on the beam particles.}
	\end{figure}
	
	The LHC beams are not continuous and are rather organised in bunch of paticles. When in $pp$-collision mode, the beams are composed of 2808 bunches of $1.15 \times 10^{11}$ protons separated by \SI{25}{ns}. When in $Pb$ collision mode, the 592 $Pb$ bunches are on the contrary composed of $2.2 \times 10^8$ ions separated by \SI{100}{ns}. The two parrallel proton beams of the LHC are contained in a single twin-bore magnet due to the space restriction in the LEP tunnel. Indeed, building 2 completely separate accelerator rings next to each other was impossible. The dipoles of the 1232 twin-bore magnets are shown in Figure~\ref{fig:LHCDipole} alongside the magnetic field generated along the dipole section to accelerate the particles. The dipoles generate a nominal field of \SI{8.33}{T}, needed to give protons and lead nucleons their nominal energy. Some 392 quadrupoles, presented in Figure~\ref{fig:LHCQuadrupole}, are also used to focus to the beams, as well as other multipoles to correct smaller imperfections.
	
	\begin{figure}[H]
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/LHC-quadrupole.jpg}
			\caption{\label{fig:LHCQuadrupole:A}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/LHC-quadrupole-field.png}
			\caption{\label{fig:LHCQuadrupole:B}}
		\end{subfigure}
		\caption{\label{fig:LHCQuadrupole} Figure~\ref{fig:LHCQuadrupole:A}: picture of the LHC quadrupoles. Figure~\ref{fig:LHCQuadrupole:B}: magnetic fields and resulting focussing force applied on the beam by 2 consecutive quadrupoles.}
	\end{figure}

	\subsection{CMS, a multipurpose experiment}
	\label{chapt2:ssec:CMS}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.55\textwidth]{fig/chapt2/CMS.jpg}
		\caption{\label{fig:CMS} Picture of the CMS barrel. The red outer layer is the muon system hosted into the red iron return yokes. The calorimeters are the blue cylinder inside in magnet solenoid and the tracker is the inner yellow cylinder built around the beam pipe.}
	\end{figure}
	
	Among the four main LHC experiment is the Compact Muon Solenoid used as a multipurpose tool to investigate the SM and physics beyond its scope. Proposed through a letter of intention in 1992~\cite{CMSLOI}, and as its name suggests, this very compact detector's uses the muons as a clear tag of most of SM and new physics interesting channels. In the original 1997 \acf{TDR}~\cite{MUONTDR}, the very first sentences were stating that \textit{"Muons are an unmistakable signature of most of the physics LHC is designed to explore. The ability to trigger on and reconstruct muons at the highest luminosities is central to the concept of CMS, the Compact Muon Solenoid."} CMS participated in the discovery of the Higgs boson and the measurement of its properties and couplings together with ATLAS and is also actively involved in the search for SUSY and heavy ion collisions. Other exotic physics are also being investigated using the data collected by CMS.
	
	The CMS apparatus in itself is the heaviest detector ever built starring a SI{15}{m} diameter and a \SI{29}{m} length for a total weight of \SI{14}{kT}. A thick \SI{4}{T} solenoid magnet located at the beam interaction point hosts trackers and calorimeters. Extending in all directions around the magnet, heavy iron return yokes are installed to extend the magnetic field and support a muon system. The apparatus consists of a barrel, referring to the magnet and the detectors contained in it and the part of the muon system built directly in the cylinder around the magnet, and of 2 endcaps in the forward and backward region of the detector that closes the apparatus and complete the detection coverage along the beam line. A front view on the barrel is provided in Figure~\ref{fig:CMS} while a detailed view of the apparatus is given in Figure~\ref{fig:CMS-detail}.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{fig/chapt2/CMS_detail.pdf}
		\caption{\label{fig:CMS-detail} View of the CMS apparatus and of its different components.}
	\end{figure}
	
	In order to efficiently detect all long leaving particles and measure their properties with good precision, the CMS detector uses an onion like layout around of the interaction point in order to maximize the covered solid angle. As detailed in Figure~\ref{fig:CMS-slice}, in the innermost region of the detector, closest to the interaction point, the silicon tracker records the trajectory of charged particles. Around it, the \acf{ECAL} stops and measure the energy deposition of electrons and photons. In the next layer, the \acf{HCAL}, hadrons are stopped are their energy measured. These layers are contained inside of the magnet of CMS, the superconducting solenoid. Outside of the magnet are the muon chambers embedded into iron return yokes used to control the magnetic field and gives muons, the only particles traveling completely through the whole detector, a double bending helping in reconstructing their energy and trajectory. Note that photons and neutral hadrons are differentiated from electrons and charged hadrons in the calorimeters by the fact  that don't interact with the silicon tracker and that they are not influenced by the magnetic field.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\textwidth]{fig/chapt2/CMS_slice.png}
		\caption{\label{fig:CMS-slice} Slice showing CMS sub-detectors and how particles interact with them.}
	\end{figure}
	
		\subsubsection{The silicon tracker, core of CMS}
		\label{chapt2:sssec:tracker}
	
	The silicon tracker visible on Figure~\ref{fig:tracker} is divided into 2 different sub-systems: the \textit{pixel detector} at the very core and the \textit{microstrip detector} around it. This system is composed of 75 million individual readout channels with up to 6000 channels per squared centimeter for the pixels making it the world's biggest silicon detector. This density allows for measurements of the particle tracks with a precision of the order of \SI{10}{\mu m}. This is necessary to reconstruct all the different interaction vertices with precision and have a precise measure of the curvature of the charged particles traveling through the magnetic field to estimate their charge and momentum.
	
	\begin{figure}[H]
		\centering
		\includegraphics[height = 4cm]{fig/chapt2/Tracker.jpg}
		\caption{\label{fig:tracker} CMS tracker.}
	\end{figure}
	
		\subsubsection{The calorimeters, measurement of particle's energy}
		\label{chapt2:sssec:calo}
	
	The ECAL directly surrounding the tracker is composed of crystals of lead tungstate, $PbWO_4$, a very dense but optically transparent material used to stop high energy electrons and photons. These crystal blocks basically are extremely dense scintillators which scintillate in fast, short light bursts proportionally to the energy deposition. The light is yielded rapidly and contained at 80\% in the corresponding \SI{25}{ns} lasting bunch crossing. Each crystal is isolated from the other by the carbon fiber matrix they are embedded in. It is composed of a barrel containing more than 60,000 crystals and of closing endcaps containing another 15,000 crystals. In front of the ECAL endcap is installed a preshower detector made out of two layers of lead and silicon strip detectors to increase the spatial resolution close to the beam line for pion-photon and single-double photon discrimination purposes. Figure~\ref{fig:ECAL} shows the calorimeter inside of the magnet and the crystals.
	
	\begin{figure}[H]
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/ECAL_barrel.jpg}
			\caption{\label{fig:ECAL:A}}
		\end{subfigure}
		\begin{subfigure}{0.5\linewidth}
			\centering
			\includegraphics[height = 4cm]{fig/chapt2/ECAL_crystals.jpg}
			\caption{\label{fig:ECAL:B}}
		\end{subfigure}
		\caption{\label{fig:ECAL} Figure~\ref{fig:ECAL:A}: picture of the ECAL. Figure~\ref{fig:ECAL:B}: picture of the lead tungstate crystals composing the ECAL.}
	\end{figure}
	
	The next layer is the HCAL measuring the hadrons momentum and providing indirect hints of non interacting neutral particles, such as neutrinos, as missing transverse momentum. Several layers of brass or steel are interleaved with plastic scintillators readout by photodiodes using wavelength-shifting fibers. The HCAL is also composed of a barrel, shown in Figure~\ref{fig:HCAL} and of endcaps. It also features forward calorimeters on both sides of CMS in the region very close to the beam line at high pseudorapidity (\psrapr{3.0}{5.0}). The role of these forward calorimeters, made using steel and quartz fibers, is to measure very energetic hadrons.
	
	\begin{figure}[H]
		\centering
		\includegraphics[height = 4cm]{fig/chapt2/HCAL.jpg}
		\caption{\label{fig:HCAL} CMS hadron calorimeter barrel.}
	\end{figure}
	
	Finally, in the outer region of the apparatus, a muon system is used to trigger on potentially interesting event by identifying muons. Indeed, the muon system is a very important part of the CMS trigger infrastructure designed to efficiently select data from the enormous data flow received by the detectors as the LHC delivers collisions at a rate of \SI{40}{MHz} with a pile-ip of 20 to 30 collisions per bunch crossing during Phase-I and up to 200 during Phase-II, representing billions of interactions per second among which a large quantity are low energy collisions that are not likely to produce new reactions, and which is physically impossible for nowadays technologies to cope with. Working at a maximum rate of \SI{100}{kHz}, the trigger system is able to select the 100,000 more interesting events by looking at the energy distribution of the interaction products and clear signatures like muons reconstructed by the muon system. the vast majority of these events will not finally be stored after physics tests are applied.
	
		\subsubsection{The muon system, corner stone of CMS}
		\label{chapt2:sssec:muon}
	
	The challenge for the muon system is to provide a robust and fast measurement of muons. Three different subsystems, and soon 4 after LS2, compose the muon system as shown in Figure~\ref{fig:Quadrant} in which a quadrant of the CMS detector focused on muon system. \acf{DT} are found in the barrel region covering the low pseudorapidity region where particles traasverse momentum is lower and \acf{CSC} are found in the endcap region covering higher pseudorapidity region closer to beam line where particles have a stronger momentum. The redundancy of the system is insured by \acl{RPC}s in both the barrel and endcap region. Nevertheless, the region closest to the beam line (\psrapg{1.8}) was not equipped with RPCs. This lack of redundancy in the high pseudo rapidity region will be solved during LS2, the following \acf{YETS} in 2021 and 2022, and LS3 where the necessary services, detectors and Link System, that collects the data and synchronizes them, will be installed.

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\textwidth]{fig/chapt2/Muon_quadrant.png}
		\caption{\label{fig:Quadrant} A quadrant of the muon system, showing DTs (yellow), RPCs (blue), and CSCs (green).}
	\end{figure}

	The barrel region is divided into 5 \textit{wheels} made out of 4 \textit{rings} of detectors with iron return yokes in between them whereas the endcaps are made out of 4 disks, each divided into pseudorapidity stations, 2 for CSCs (except for the first disk where 3 stations are equipped) and 3 for RPCs, although only 2 RPCs stations are equipped at present. The wheels and disks are shown in Figure~\ref{fig:Muon}. So far, each subsystem was dedicated to a particular task. DTs, in the barrel, and CSCs, in the endcaps, are used mainly for their spatial resolution. Indeed, DTs' resolution is of the order of \SI{100}{\micro m} along both the $(r-\phi)$ and $(r-z)$ components while the resolution of CSCs is similar but varies in a range from \SI{50}{\micro m} to \SI{140}{\micro m} depending on the distance to the beamline. On the other hand, RPCs are used for their time resolution as they can deliver an information on the muon tracks within \SI{1.5}{ns}.
	
	\begin{figure}[H]
		\begin{subfigure}{0.35\linewidth}
			\centering
			\includegraphics[height = 6cm]{fig/chapt2/Wheel.jpg}
			\caption{\label{fig:Muon:A}}
		\end{subfigure}
		\begin{subfigure}{0.3\linewidth}
			\centering
			\includegraphics[height = 6cm]{fig/chapt2/Disk_CSC.jpg}
			\caption{\label{fig:Muon:B}}
		\end{subfigure}
		\begin{subfigure}{0.35\linewidth}
			\centering
			\includegraphics[height = 6cm]{fig/chapt2/Disk_RPC.jpg}
			\caption{\label{fig:Muon:C}}
		\end{subfigure}
		\caption{\label{fig:Muon} Figure~\ref{fig:Muon:A}: Barrel wheel with its detector rings and return yokes. Figure~\ref{fig:Muon:B}: CSC endcap disk with the 2 CSC stations. The outer station is made of \SI{10}{\deg} detectors while the inner station is made of \SI{20}{\deg} detectors. Figure~\ref{fig:Muon:C}: RPC endcap disk. The inner station is not equipped and the inner CSC station can be seen.}
	\end{figure}
	
	\begin{figure}[H]
		\begin{subfigure}{0.6\linewidth}
			\centering
			\includegraphics[height = 4.5cm]{fig/chapt2/DT_layout.png}
			\caption{\label{fig:DT:A}}
		\end{subfigure}
		\begin{subfigure}{0.4\linewidth}
			\centering
			\includegraphics[height = 4.5cm]{fig/chapt2/DT_cells.png}
			\caption{\label{fig:DT:B}}
		\end{subfigure}
		\caption{\label{fig:DT} Figure~\ref{fig:DT:A}: Cross section of a DT module showing the two superlayers measuring the $\phi$ coordinate, perpendicular to the cross section plane, and the superlayer measuring the $\eta$ coordinate, placed in between the two others with honeycomb and parallel to the cross section plane. The DT detector is sandwiched in between 2 RPCs whose readout strips are perpendicular to the cross section plane, measuring the $\phi$ coordinate. Figure~\ref{fig:DT:B}: A DT cell is shown together with its electric field. The path of a muon through a superlayer is shown.}
	\end{figure}
	
	The 250 CMS DTs, found in the barrel covering the pseudorapidity region \psrapr{0}{1.2} and whose structure is shown in Figure~\ref{fig:DT}, are composed of 3 \textit{superlayers} of DT cells. Two of these superlayers are dedicated to measuring the $\phi$ coordinate of the muons and while the last one measures the $\eta$ (or $z$) coordinate. Each superlayer consists on 4 layers of 60 to 70 DT cells arranged in quincunx to allow for a precise reconstruction of the muon path through the DT layers. Each DT cell is a rectangular aluminium gas volume with a central anode wire. Cathode strips are placed on the narrow surface of the cells and electrode strips are placed on the wide surface to help shaping the electric field to ensure a consistent drift velocity of electrons in the drift volume. These detectors are operated using a 85/15 mixture of $Ar$ and $CO_2$.
	
	\begin{figure}[H]
		\begin{subfigure}{0.4\linewidth}
			\centering
			\includegraphics[height = 5cm]{fig/chapt2/CSC_layout.png}
			\caption{\label{fig:CSC-layout:A}}
		\end{subfigure}
		\begin{subfigure}{0.6\linewidth}
			\centering
			\includegraphics[height = 5cm]{fig/chapt2/CSC_avalanche.png}
			\caption{\label{fig:CSC-layout:B}}
		\end{subfigure}
		\caption{\label{fig:CSC-layout} Figure~\ref{fig:CSC-layout:A}: cathode strips and anode wire layout of a CSC panel. Figure~\ref{fig:CSC-layout:B} avalanche development and charge collection by anode wires and induction on cathode strips inside of a CSC panel.}
	\end{figure}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=\textwidth]{fig/chapt2/CSC_track.png}
		\caption{\label{fig:CSC-track} Muon track reconstruction through the 6 panels of a CMS CSC using the information of anode wire groups and cathode strip charge distribution combined with comparator bits to decide on which half strip the muon is more likely to have passed.}
	\end{figure}
	
	The 540 CMS CSCs, found in the endcaps covering the pseudorapidity region \psrapr{0.9}{2.5} and described through Figures~\ref{fig:CSC-layout} and \ref{fig:CSC-track}, are composed of 6 panels of CSC, each panel consisting in a wide gas volume of \SI{9.5}{mm} (\SI{7}{mm} in the case of ME1/1 station) containing anode wires and whose surfaces are cathodes. The top cathode is a wide copper plane of the size of the gas volume. The bottom cathode is divided into thin trapezoidal copper strips radially arranged to measure the azimuthal coordinate $\phi$ with a pitch ranging from 8 to \SI{16}{mm}. The \SI{0.50}{\micro m} anode wires are placed perpendicularly to the strips to measure radial coordinate $r$ and are grouped by 10 to 15 with a wire to wire space of \SI{3.2}{mm}. In he specific case of ME1/1 placed against the HCAL endcap, the \SI{0.30}{\micro m} anode wires have a wire to wire distance of \SI{2.5}{mm} and are not disposed perpendicularly to the strips but slightly tilted by an angle of \SI{29}{\deg} to compensate for the lorentz force due to the very strong local magnetic field of \SI{4}{T}. These detectors are operated with a 40/50/10 mixture of $Ar$, $CO_2$ and $CF_4$. Combining the information of the multiple CSC panels, the detectors achieve a very precise measurement of the muon track.
	
	Despite their excellent spatial resolution, the wire chambers (DTs and CSCs) are limited in terms of time resolution by the fact that the charge needs to drift towards the anode wire and be collected before having the confirmation that a particle was detected as the drift volume is not used to develop avalanches. Indeed, the stronger electric field close to the anode wire triggers the avalanche and the gain of the detector. Due to the drift, the time resolution is thus limited at best to approximately 2 to \SI{3}{ns}. In addition, even though the intrinsic time resolution of the tracking chambers is rather good compared to the \SI{25}{ns} in between successive collisions, the processing time of the trigger system doesn't allow for very fast triggering as it provides a time precision of only \SI{12.5}{ns}. Thus, detectors fully dedicated to timing measurement have been installed as a redundant system. These detectors are RPCs, also gaseous detectors but that use current induction instead of charge collection allowing for a time resolution of the order of \SI{1.5}{ns} only. Theoretically, depending on the design used, RPCs could reach a time resolution of the order of \SI{10}{ps} but in the context of LHC where bunch crossing happen every \SI{25}{ns}, a time resolution of \SI{1.5}{ns} is sufficient to accurately assign the right bunch crossing to each detected muon.
	
	The 1056 RPCs equipping the CMS muon system both in the barrel and endcap regions and covering the pseudorapidity region \psrapr{0}{1.6} are composed of two layers of RPC \textit{gaps} as described in Figure~\ref{fig:RPC-DG-layout}. Each gap consists in two resistive electrodes made out of \SI{2}{mm} thick Bakelite enclosing a \SI{2}{mm} thick gas volume containing a 95.2/4.5/0.3 mixture of $C_2H_2F_4$, $i-C_4H10$ and $SF_6$. Due to this geometry, the electric field inside of a gap is homogeneous and linear at every point in the gas translating into a uniform development of avalanches in the gas volume as soon as a passing muon ionises the gas. The two gaps sandwich a readout copper strip plane. A negative voltage is applied on the outer electrodes, used as cathodes, and the inner electrodes, the anodes, are simply connected to the ground as well as the readout panel that picks up the current induced by the accumulated charge of the growing avalanches in one or both of the gas gaps. This OR system allows for a lower gain (i.e. a lower electric field) on both gaps to reach the maximal efficiency of such a detector.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\textwidth]{fig/chapt2/RPC_DG_layout.png}
		\caption{\label{fig:RPC-DG-layout} Double gap layout of CMS RPCs. Muons passing through the gas volumes will create electron-ions pairs by ionising the gas. this ionisation will immediately translate into a developing avalanche.}
	\end{figure}

\clearpage{\pagestyle{empty}\cleardoublepage}